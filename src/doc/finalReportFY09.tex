\documentclass{report}

\pdfpagewidth 8.5in
\pdfpageheight 11in
\setlength\topmargin{0.25in}
% \setlength\headheight{0in}
% \setlength\headsep{0in}
\setlength\textheight{8.5in}
\setlength\textwidth{6in}
\setlength\oddsidemargin{0.25in}
\setlength\evensidemargin{0.25in}
% \setlength\parindent{0.25in}
% \setlength\parskip{0.25in} 

\pagestyle{headings}
\usepackage{url}
\usepackage[dvips]{graphicx}

\author{Geoff Lawler \url{<geoff.lawler@cobham.com>} \\ SPARTA, Inc. dba Cobham Analytic Solutions}
\title{{\bf Visualization Tool Improvements for the Wireless Emulation Lab (WEL) Project}\\Final Report FY09}
% \subtitle{The Search for Spock}

\begin{document}
\maketitle

\renewcommand*\thesection{\arabic{section}}

\section{Introduction}

``The Watcher'' is a mobile ad-hoc network (MANET) visualization tool that allows researchers to visualize the locations and states of nodes in an emulated MANET environment. The Watcher was originally written 
as a quick and dirty debugging tool used to verify that the MANET emulation tools were working properly. By being able to visualize the locations of the nodes, it was easy to 
tell if the mobility scenario was working and the node connectivity appeared correct. Quickly after this the ability to display text labels on nodes and edges of the connectivity 
graph was added to enable researchers to debug the inner workings of the MANET security tools they were developing on their MANET emulation test beds. The ability to display labels
allowed the state of any node to be seen at a glance. The Watcher was found to be a useful tool and was used by a fair number of researchers in the community. 

In the summer of 2008, ARL approached SPARTA, Inc. dba Cobham Analytic Solutions\footnote{On June 3, 2008, SPARTA, Inc. completed a merger with Cobham, plc a United Kingdom (UK) 
public company. SPARTA Inc. is a wholly owned subsidiary of Cobham North America. SPARTA Inc. is doing business as Cobham Analytic Solutions}
(hereafter referred to as Cobham) with the idea of funding a small project not only to enhance the Watcher in order to make it a better tool for research, but also to enhance 
its graphics for use in demos. The contract and statement of work were finalized and a kickoff meeting was held in August of 2008. Now in August of 2009 the contract is ending and 
this report summarizes the work done, findings, and possible future directions for Watcher improvements. 

Figure \ref{fig:oldWatcher} shows the Watcher tool at the start of the improvements project. Figures \ref{fig:legWatcherGUI} and \ref{fig:watcherWithBackground}
show the Watcher towards the end of the improvements contract. Note that the GUI is now in a window and contains user interface elements such as buttons, menus, and playback
mechanism, a background image, and other graphical and user interface improvments. Because of updates to the Watcher architecture, it is now possible to have multiple distinct GUIs displaying the same (live or recorded) data. So in addition to improving
work on the original Watcher GUI, some work was done exploring more advanced graphical development environments and writing new Watcher GUIs from scratch. (This is why the original
GUI is sometimes referred to as the ``legacy Watcher''.) A proof of concept using an advanced game-engine can be seen in Figure \ref{fig:ogreWatcherGUI}. 

\begin{figure}[htb]
\centering
\includegraphics[width=0.5\textwidth]{oldWatcher.eps}
\caption{Watcher at start of project}
\label{fig:oldWatcher}
\end{figure}

\begin{figure}[htb]
\centering
\includegraphics[width=0.5\textwidth]{legWatcherGUI.eps}
\caption{Watcher GUI at end of project. Note user interface widgets, playback buttons and slider, menus, framed window.}
\label{fig:legWatcherGUI}
\end{figure}

Below are three sections that give an overview of the work done in the last year on the Watcher Improvements project. First
is the work accomplished---what was done and why. This is followed by a section on lessons learned from the work done. What is now known 
that was not known then? What would be done differently if given the chance? The final section gives a recommendation on future directions
for the project: where the Watcher system may go and how it can get there. 

\section{Work Performed}

The main Watcher GUI had many updates and fixes applied in the first half of the contract. This portion of the time was focused on updating the GUI to 
support usability and display features for the Army Science Conference in December 2008. Thus the focus was on modifying the existing code base---fixing bugs 
and adding features requested by ARL. The last six months of the contract focused much more on the new architecture, full ``TiVo'' mode, and removing 
the reliance on the idsCommunications hierarchy daemons as a transport mechanism. The second half of the contract saw a large amount of code written, new GUIs developed, and 
a near complete rewrite of the existing Watcher GUI. 

\subsection{Watcher Improvements--First Half}
The first half on the contract focused on improvements and bug fixes to the existing code base to support the Army Science conference.  

\begin{itemize}
\item Wrapped the OpenGL window in a Qt window, giving us modern GUI widgets. 
\item Use mouse to control movement in the main Watcher window.
\item More modular logging. Good for debugging and general system performance.
\item Graphical primitives in Watcher window are 3D. Can toggle between 3D and 2D via a menu.
\item Added ability to load a background image into main Watcher GUI window and place it as needed via the mouse.
\item Watcher GUI saves state to human readable configuration file on exit. This file is also read on start and Watcher honors the 
settings found there. File can be edited to modify Watcher GUI behavior.
\item Test nodes can control how they are represented in the GUI (shape, size, color, flashing, spinning, blinking). These representations
are saved in the Watcher configuration file.
\item Can use the mouse to select a node in the GUI.

\item Background color of the GUI can be changed at run-time. New color is saved in Watcher configuration file.
\item Added 2D scrolling graph to Watcher GUI. Test nodes send periodic data to the Watcher. The Watcher saves this information and when 
a user clicks on a node, the data stored by the Watcher is displayed. Multiple test nodes' data can be displayed at once and the graph
works in real time, as new data comes in, the old data is scrolled off the end of the graph dialog. Multiple types of period data 
are supported.  (The set of types was hard-coded, but in the second half of the project, these were made dynamic.) See Figure \ref{fig:watcherBandwidthGraphDialog} 
for an example snapshot.

\begin{figure}[htb]
\centering
\includegraphics[width=0.4\textwidth]{watcherBandwidthGraphDialog.eps}
\caption{Example of 2D scrolling graph in ``legacy'' Watcher GUI showing data from 2 test nodes.}
\label{fig:watcherBandwidthGraphDialog}
\end{figure}

\end{itemize}

\begin{figure}[htb]
\centering
\includegraphics[width=0.5\textwidth]{watcherWithBackground.eps}
\caption{``legacy'' Watcher graphics window showing background and 3D primitives.}
\label{fig:watcherWithBackground}
\end{figure}

\subsection{Watcher Improvements--Second Half}
The second half of the contract focused on redesign and writing a new code base. A new Watcher architecture was designed and developed. It was 
designed for extensibility and scalability, to easily support full ``TiVo'' mode, to provide a fully dynamic system, and to remove reliance
on the hierarchy as a transport mechanism. Below is a list of highlights from this half of the project. The next section (\ref{newArch}) gives a few more details
on the new architecture.

\begin{itemize}
\item Wrote new Watcher messaging system including message parsing, protocols, and message formats from scratch. 
\item Split message handling, message playback, and message caching from graphical representation. Architecture now
supports a single daemon and multiple different GUIs. 
\item Watcher daemon now uses a database to store messages for playback instead of the binary file format. This allows
flexibility, efficient random access, and the ability of third-party applications to process Watcher data. 
\item Rewrote all network code, creating the Watcher daemon and removing GUI reliance on hierarchy. Network functionality is now
much more scalable. 
\item Wrote proof-of-concept Watcher GUI based on the Object-Oriented Graphical Rendering Engine (OGRE) (\url{www.ogre3d.org}). See Figure \ref{fig:ogreWatcherGUI} for a
screen shot. (Note that the robots can be easily swapped out for tanks or other more suitable figures.) The proof-of-concept supports adding nodes and edges, and 
correctly moving the nodes around. It does not support labels, layers, or any configuration information. 

\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{ogreWatcherGUI.eps}
\caption{First cut at game engine-based Watcher GUI. Note realistic environment. Game engines allow for more sophisticated graphics and user interaction.}
\label{fig:ogreWatcherGUI}
\end{figure}

\item The Watcher GUI now supports fully dynamic layers and graph data. (Every GUI primitive such as nodes, edges, and layers are assigned a layer. Each layer can be
toggled via the layer menu. The graph data is the periodic data fed from the test nodes and the title of the graph.) No layer or graph data is hard-coded in the Watcher system, all 
the layer and graph data is fed directly from test nodes and handled in the GUI in a simple and systematic way. New layers and graph titles show up dynamically in the appropriate 
menus. The menus are populated from live test node data or configuration data from a previous run.
\item Investigated use of Google Earth for a Watcher system GUI. It appears feasible. It will lack smoothness in display (refresh times are once a second), but it 
does have nearly perfect graphics for a Watcher GUI, good user interaction, and built-in layers. Offline caching of images, for offline test bed controllers, should work. 
\item Investigated the Delta-3D game engine (\url{www.delta3d.org}) as the basis of a new Watcher GUI. Wrote proof-of-concept application. Delta3D and OGRE would both make 
a fine basis for a Watcher GUI. The build and development environment for Delta-3D is more Windows oriented though. 
\item Wrote test node daemon that runs on test nodes and converts old hierarchy-based Watcher messages into new message format. 
This means that old Watcher-aware daemons do not have to be updated to support the new transport mechanism.
\item Wrote new Watcher GPS daemon that supports the new GPS daemon that {\it eMANE} uses (gpsd). 
\end{itemize}

\begin{figure}[!b]
\centering
\includegraphics[width=0.8\textwidth]{watcherArch.eps}
\caption{New Watcher system architecture. Is much more scalable and extensible. Supports multiple GUIs, database oriented record and playback, ``TiVo'' like message streaming APR.} 
\label{fig:watcherArch}
\end{figure}

\subsection{New Architecture}
\label{newArch}

The Watcher architecture was redesigned and abstracted to promote flexibility, extensibility, and scalability.  Divorcing the record 
capability from the display mechanism allowed us to easily add full ``TiVo'' capability (pause\slash fast-forward\slash rewind) and the ability to have multiple 
GUIs with independent views into the same data set. One researcher can view a test run which focuses on a single node or region, 
pausing and fast-forwarding a single section of the playing field while another researcher can view it all or jump from 
location to location, viewing multiple different layers of the data set. See Figure \ref{fig:watcherArch} for a diagram 
of the new architecture.

Abstracting the layer concept allows the researcher to add layers dynamically at run-time. For example, 
if a researcher notices a problem with bandwidth usage, he or she can easily write a new test node daemon that 
adds a new ``bandwidth'' layer to the data set. This new layer shows up in the GUI and can be toggled as needed. 
Compare this to the old Watcher which had a fixed, hard-coded set of layers regardless of the components of the test
or the researcher's needs. The old Watcher always had a ``wormhole attacks'' layer even if the test did not 
contain the wormhole detector or even anything wormhole related at all. 

Another benefit to the new architecture is that the system is much more dynamic. The old Watcher needed to know all the addresses of all the nodes
on the testbed. This information was even needed when a session was played back. The new system is much more adaptive---any node can connect and 
send or request data at any time. 

\section{Lessons Learned}
Since this was a software development related project many of the lessons learned were standard development lessons as applied to the 
specific technologies in the Watcher. These mostly stemmed from misunderstanding the technology or not anticipating specific cases. 
But in addition to the ``negative'' lessons, there were positive lessons learned as well. Instances where our decisions were affirmed were
relatively frequent and told us we were on the correct path. 

We settled on using the Boost C++ library as it has very good support for writing robust, scalable network applications (the ASIO library). In addition
to ASIO, Boost comes with a wide variety of other well-written libraries. So it was decided to use as Boost as much as possible as it is stable, standard, and, portabile. 
Boost generally impressed with one major exception: the serialization library. All messages that go on the wire need to be serialized and unserialized. All Watcher 
messages use the Boost serialization library to do
this. It was thought that since serialization is a (pretty) simple task, there would be few problems. But it turned out that this library caused us the most headaches 
of any of the other third-party libraries we used. The library is fragile and difficult to use when embedding in libraries, which we use for the Watcher messages as they 
cross component boundaries. After consulting not overly helpful online forums and documentation, we discovered (for technical reasons) that the library had to be a shared 
dynamically linked library. Once we made that change, it worked correctly. 

The rest of the Boost library worked well. We believe the new Watcher daemon, which uses the Boost ASIO network library will be able to scale
to multiple hundred, if not thousands of nodes. That being said, this had not been fully tested. 

In general, the new architecture has been validated. The decoupling of graphic rendering from message processing has worked out well. The Watcher system
appears to work as advertised. The use of a database in place of a binary file allows us to process the events in a more reasonable manner. (This will give
more benefits if we move the system into a test bed analysis direction.) The system can successfully and cleanly handle multiple GUI instances and binaries 
viewing independent test bed times and locations. The message stream idea has even been extended to include multiple shared streams and shared stream events
which will support multiple GUIs and analysis tools viewing and controlling the same data stream. Although this idea has not been implemented it validates
the architecture when such thoughts can be discussed and envisioned. The message stream interface was validated as well given the ease with which it 
was integrated in the proof-of-concept OGRE-based Watcher GUI and {\it messageStream2Text} debugging utility. 

The investigation into different game engine tool kits has been enlightening. It has helped us narrow in on a more specific functionality set that is needed
for a Watcher GUI. Many game engines have a feature set that is almost too full, a feature set that contains things a Watcher GUI will not need, such as 
a networking suite. Since the Watcher uses the network library written just for it, the game engine supplied networking library is not needed. The overhead in supporting 
some game engines overly full
feature set may be too much (or at least unnecessary) for Watcher GUI development. For example, the Delta3D suite is essentially as small standard 
interface around a number of different libraries. This interface while uniform may not fit all modules in the system. Also having to build and install
all the modules can be tedious and time consuming. A more focused library such as OGRE, may be better suited for Watcher GUI development. It is just 
a graphical engine. (It does have semi-well integrated hooks for needed modules like user input and a windowing system though.) That being said, an expert 
in Delta3D could write a Watcher GUI quickly -- but since the development team did not have any experience in game\slash graphical engines prior to 
this project, the feature set focus was useful. 

In the original Watcher, the build environment was based on Makefiles. This is a fine approach for small projects, which the Watcher was, but as it grew
in number of components and dependencies the decision was made to move to a GNU auto-tools based build environment. This greatly simplified a number
of things. The ability to add and check the build machine for dependencies was straightforward. Previously the build environment would simply fail to link
if a needed dependency was not installed. The auto-tools system checks for dependencies as a first step and provides a straight-forward, abstracted way 
to add new dependencies to a project. In addition, it helped developers spin up more quickly as a template was available for new modules as the existing
Makefile.am could simply be copied and adapted. This allows developers to focus more quickly on the task at hand with out having to figure out how to 
compile their code. 

There were a few assumptions in the build environment that caused trouble when building the system at ARL. Auto-tools abstracts the locations
of key files (system libraries, etc.) and build variables (compiler flags, etc.). In our configuration we ignored this a few times when looking 
for libraries we used. This was for our own convenience. Different developers put different third-party libraries in different locations. We hard-coded
a few of these locations into the configuration scripts. We assumed there would be no issues as the places we listed included system paths and most
installations would be in standard system locations. At ARL though, the NiCE system is used in which multiple versions and platforms of each library
is built and installed in version and platform specific locations in the file system. So our build system failed to find the libraries when building 
at ARL. These issues have been resolved by updating the configure scripts in the Watcher code tree. 

\section{Recommendations for Future Work}
As part of the wrap-up of the Watcher Improvements project, Cobham in consultation with ARL came up with a list of tasks and directions
the Watcher Improvements project could implement if the project is funded for another year. A version of this list is presented below. It is 
broken up into four different categories: scalability, Watcher as analysis tool, GUIs, and Watcher as controller. 
At current funding levels, not all of these tasks and directions would be possible. Think of this list as a starting point for further
discussion. If the project is re-funded, some subset of these ideas will be refined and included in a final Statement of Work. 

\begin{enumerate}
\item Scalability 
\begin{enumerate}
    \item Network 
    \begin{enumerate}
        \item Test-node data filtering (nodes do not send all possible data all the time). This includes a modification to the existing watcherd API to support data-filtering directives sent to the test nodes.  A further extension of this concept would be a ``distributed Watcher DB,'' where data would be pulled from test nodes ``on demand'' (as the GUI currently does from the central Watcher DB).
        \item Write Watcher data locally at test nodes, then collect and merge post-test. Used to minimize bandwidth usage or support cases where there is no control network at all. Each test node records its own data, which is then merged post test into a ``normal'' Watcher DB, which is then used to view the entire test run.
         \item Test with 1,000s (or 10,000s (or more)) of nodes and fix general network\slash packet\slash compression issues that arise. This would be done simulating 1000s of nodes at Watcher's test node API. 
    \end{enumerate}
    \item Graphics (GUI) 
    \begin{enumerate}
        \item Levels of focus. As camera pulls back, graphical units are ``clumped'' together in one unit. User can get detailed view by clicking. New view would be overlaid `exploded' view or zoomed-in view in new window. This would be added to legacy Watcher GUI and/or the game engine GUI (if needed). 
        \item Add per-zoom-level images (Google Earth like behavior) to existing background image in legacy Watcher. Currently the legacy only has a static background image. This task would add an image per zoom level---thus ``zooming'' in or out of the background image, enabling high resolution at tighter zoom levels without causing excessive memory usage or performance problems in wide views. 
        \item Better user interface for choosing and focusing on node groups. Highlight\slash drag mouse to choose\slash make groups. Display only groups or subsets of groups. Only display nodes\slash edges by region, layers, role, type, etc. This would be more easily implemented in the game engine GUI, but can be added to legacy Watcher if needed.
        \item Area context menu in corner of GUI shows global view when zoomed. This task is for both the legacy Watcher and the game engine Watcher. 
    \end{enumerate}
    \item WatcherAPI
    \begin{enumerate}
        \item Write a python interface to the Watcher system. This enables rapid prototyping of new test node daemons and GUIs. (Note: This task does not really properly fit under the ``scalability'' heading, except in that large-scale network monitoring is more likely to benefit from easily customized tools and views.)
    \end{enumerate}
\end{enumerate}
\item Watcher as Analysis Tool 
    \begin{enumerate}
    \item Work seamlessly with other test bed analysis tools.
        \begin{enumerate}
            \item Ability to spawn any GUI at a specific time, place, zoom level, in test as directed by outside tool\slash script\slash user. The ``what was happening at time $t$?'' option. For this task an API for this specific purpose would be developed.  
            \item Tools to parse\slash combine different testbed databases, including the Watcher DB.
            \item Ability to share copies of streams between GUIs---subscribe to streams. This enables different GUIs (be they Watcher GUIs or analysis tools) to view and control the same data stream at the same time. For this task, the existing Watcher message stream API would be expanded to support publish\slash subscribe semantics. Also publish\slash subscribe tools would be written to show existing published streams (to facilitate subscribing to them).
            \label{streamSharingFollowon}
        \end{enumerate}
        \item Combined with \ref{streamSharingFollowon}, add an API to share events between different GUIs subscribed to the same data stream. Click, or cause an event, on a node in one GUI and that event is broadcast to all other GUIs listening to the same stream. Click on a node in the analysis tool, and the Watcher highlights it (or takes another action). For this task the existing watcherd API would be expanded to include this 'Watcher event' model.
        \item Data-visualization-agnostic system. Test nodes send data, and Watcher displays it without having to know what the data is. Leverage third-party data visualization tools\slash libraries within Watcher GUI (VTK). Use Watcher transport mechanism as a data feeder; use Watcher GUI as a tool driver\slash data visualizer. This task would add NETDMF support to the existing watcherd API and GUI of choice. 
        \item Write custom analysis tools---interactive version of existing wormhole analysis tools integrated into a Watcher GUI.
\end{enumerate}
\item GUIs 
\begin{enumerate}
    \item Continue work on game engine based GUI as needed and driven by other tasks chosen. 
    \item Continue to refine ``legacy Watcher'' as needed and directed by ARL and other tasks chosen.
    \item Integrate known\slash existing terrain models. This task would add terrain models to the game engine GUI and if needed (taking much more time) into the legacy Watcher.
    \item Integrate wireless models, radio types, and other physical models. Expand existing ``antenna radius'' to show more realistic loss models, possibly imported directly from third-party tools. This task would expand existing antenna radius view in legacy Watcher or add the view to the game engine GUI. In either case, it would give more realistic view of packet loss due to environment. Data for this view would be directly imported from tools that generated the loss model. 
    \item Role based nodes. Nodes (and possibly other graphical elements) will possess a configurable set of attributes that are based on the role of the node in the scenario. (US forces in blue, coalition forces in green, soldiers shown with rank, etc). The attributes and roles can then be used to drive, if needed, selecting\slash grouping\slash hiding\slash etc.\ the nodes in the GUI.   
    \item Integrate NASA World Wind or other earth imagery into non Google-Earth based GUI, the legacy Watcher or game engine Watcher as needed. 
\end{enumerate}
\item Watcher as Controller 
\begin{enumerate}
    \item Use Watcher to control mobility scenario (pause, fast-forward, rewind) while live test is running (control MANE\slash eMANE gps servers). Seems a natural fit as Watcher already has TiVo mode controls and views tests in real time. 
    \item Generic issue-command-to-test-node-or-set-of-test-nodes functionality. Combine with better group focus (1.2.3) and issue shell commands (or other) to test nodes. (Watcher as cmdThem\slash mob interface). Right-click on node and send typed-in shell command. This task would most likely be implemented by integrating Jos\'{e}'s testbed control API into the legacy Watcher or game engine Watcher as needed. 
\end{enumerate}
\end{enumerate}

\section{Conclusion}

% The Watcher is awesome!

The FY09 Watcher Improvements effort has made substantial progress
in taking the Watcher from a basic prototype towards becoming a
powerful, extensible, efficient, scalable, and polished system for advanced MANET
research and experimentation. The lessons learned on this project have given the 
development team insight into techniques and technologies needed to expand the prototype 
into a flexible working system for MANET visualization.  The follow-on tasks proposed here
promise to provide important new capabilities for understanding
large-scale MANETs, integrating with third-party tools, presenting 
more realistic and compelling visualizations, and moving beyond passive 
monitoring to active experiment control and test analysis. 

\end{document}
